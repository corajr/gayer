// Generated by BUCKLESCRIPT VERSION 4.0.3, PLEASE EDIT WITH CARE

import * as Curry from "bs-platform/lib/es6/curry.js";
import * as React from "react";
import * as Caml_array from "bs-platform/lib/es6/caml_array.js";
import * as Audio$Gayer from "./Audio.bs.js";
import * as ReasonReact from "reason-react/src/ReasonReact.js";
import * as Canvas$Gayer from "./Canvas.bs.js";
import * as Js_primitive from "bs-platform/lib/es6/js_primitive.js";
import * as Belt_MapString from "bs-platform/lib/es6/belt_MapString.js";
import * as AudioGraph$Gayer from "./AudioGraph.bs.js";
import * as TypedArray$Gayer from "./TypedArray.bs.js";

function drawRawAudioFloat(layerRefs, state, x, y, width, height) {
  state[/* analyser */0][0].getFloatTimeDomainData(state[/* audioDataFloat */1][0]);
  var outputImageData = new ImageData(TypedArray$Gayer.float32toUint8ClampedArray(state[/* audioDataFloat */1][0]), width, height);
  var match = Belt_MapString.get(layerRefs[0], "root");
  if (match !== undefined) {
    var ctx = Js_primitive.valFromOption(match).getContext("2d");
    ctx.putImageData(outputImageData, x, y);
    return /* () */0;
  } else {
    return /* () */0;
  }
}

function drawRawAudioUint8(_, channel, state, _$1, _$2, width, height) {
  var audioDataByte = state[/* audioDataByte */2][0];
  var n = audioDataByte.length;
  var audioDataByteForImage = state[/* audioDataByteForImage */3][0];
  state[/* analyser */0][0].getByteTimeDomainData(audioDataByte);
  var channelOffset = Canvas$Gayer.int_of_channel(channel);
  for(var i = 0 ,i_finish = n - 1 | 0; i <= i_finish; ++i){
    Caml_array.caml_array_set(audioDataByteForImage, (i << 2) + channelOffset | 0, Caml_array.caml_array_get(audioDataByte, i));
    Caml_array.caml_array_set(audioDataByteForImage, (i << 2) + 3 | 0, 255);
  }
  var outputImageData = new ImageData(audioDataByteForImage, width, height);
  var match = state[/* canvasRef */4][0];
  if (match !== undefined) {
    var ctx = Js_primitive.valFromOption(match).getContext("2d");
    ctx.putImageData(outputImageData, 0, 0);
    return /* () */0;
  } else {
    return /* () */0;
  }
}

var component = ReasonReact.reducerComponent("AnalysisCanvas");

function make(samples, width, height, saveTick, layerKey, layerRefs, audioCtx, encoding, audioGraph, setRef, x, y, _) {
  var setCanvasRef = function (theRef, param) {
    var state = param[/* state */1];
    state[/* canvasRef */4][0] = (theRef == null) ? undefined : Js_primitive.some(theRef);
    Curry._1(setRef, theRef);
    return Curry._3(saveTick, param[/* onUnmount */4], layerKey, (function () {
                  if (encoding) {
                    return drawRawAudioUint8(layerRefs, encoding[0], state, x, y, width, height);
                  } else {
                    return drawRawAudioFloat(layerRefs, state, x, y, width, height);
                  }
                }));
  };
  return /* record */[
          /* debugName */component[/* debugName */0],
          /* reactClassInternal */component[/* reactClassInternal */1],
          /* handedOffState */component[/* handedOffState */2],
          /* willReceiveProps */component[/* willReceiveProps */3],
          /* didMount */(function (self) {
              audioGraph[0] = AudioGraph$Gayer.updateConnections(AudioGraph$Gayer.addEdge(/* tuple */[
                        layerKey + "input",
                        layerKey,
                        0,
                        0
                      ], AudioGraph$Gayer.addNode(/* tuple */[
                            layerKey,
                            self[/* state */1][/* analyser */0][0]
                          ], audioGraph[0])));
              return Curry._1(self[/* onUnmount */4], (function () {
                            audioGraph[0] = AudioGraph$Gayer.updateConnections(AudioGraph$Gayer.removeAllEdgesInvolvingNode(layerKey, AudioGraph$Gayer.removeNode(layerKey, audioGraph[0])));
                            return /* () */0;
                          }));
            }),
          /* didUpdate */component[/* didUpdate */5],
          /* willUnmount */component[/* willUnmount */6],
          /* willUpdate */component[/* willUpdate */7],
          /* shouldUpdate */component[/* shouldUpdate */8],
          /* render */(function (self) {
              return React.createElement("canvas", {
                          ref: Curry._1(self[/* handle */0], setCanvasRef),
                          style: {
                            position: "absolute",
                            visibility: "hidden"
                          },
                          height: height.toString(),
                          width: width.toString()
                        });
            }),
          /* initialState */(function () {
              console.log("Raw audio canvas initialized. Using FFT of size " + samples.toString());
              var analyser = Audio$Gayer.makeAnalyser(audioCtx, samples, undefined, undefined, undefined, /* () */0);
              return /* record */[
                      /* analyser : record */[/* contents */analyser],
                      /* audioDataFloat : record */[/* contents */new Float32Array(samples)],
                      /* audioDataByte : record */[/* contents */new Uint8Array(samples)],
                      /* audioDataByteForImage : record */[/* contents */new Uint8ClampedArray((samples << 2))],
                      /* canvasRef : record */[/* contents */undefined],
                      /* timerId : record */[/* contents */undefined]
                    ];
            }),
          /* retainedProps */component[/* retainedProps */11],
          /* reducer */(function (_, _$1) {
              return /* NoUpdate */0;
            }),
          /* subscriptions */component[/* subscriptions */13],
          /* jsElementWrapped */component[/* jsElementWrapped */14]
        ];
}

export {
  drawRawAudioFloat ,
  drawRawAudioUint8 ,
  component ,
  make ,
  
}
/* component Not a pure module */
